{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df2fe7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T15:15:44.922743Z",
     "iopub.status.busy": "2025-07-24T15:15:44.922411Z",
     "iopub.status.idle": "2025-07-24T15:16:34.483718Z",
     "shell.execute_reply": "2025-07-24T15:16:34.482764Z"
    },
    "papermill": {
     "duration": 49.56653,
     "end_time": "2025-07-24T15:16:34.485197",
     "exception": false,
     "start_time": "2025-07-24T15:15:44.918667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score on validation data: 0.9802896272530597\n",
      "Mean Squared Error on validation data: 931680178976162.0\n",
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/engage-2-value-from-clicks-to-conversions/train_data.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/engage-2-value-from-clicks-to-conversions/test_data.csv')\n",
    "subm_df = pd.read_csv('/kaggle/input/engage-2-value-from-clicks-to-conversions/sample_submission.csv')\n",
    "\n",
    "train = train_df.loc[:, train_df.nunique() != 1]\n",
    "test = test_df.loc[:, test_df.nunique() != 1]\n",
    "\n",
    "# Drop duplicates\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "train_clean = train.loc[:, train.isnull().mean() < 0.5]\n",
    "test_clean = test.loc[:, test.isnull().mean() < 0.5]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = [ 'trafficSource.campaign', 'geoNetwork.networkDomain', 'geoNetwork.region',\n",
    "                'geoNetwork.city', 'geoNetwork.metro' ]\n",
    "train.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Define column types for preprocessing\n",
    "categorical_columns = ['browser', 'trafficSource.keyword', 'os', 'geoCluster', \n",
    "                       'trafficSource', 'trafficSource.medium', 'trafficSource.referralPath',\n",
    "                       'deviceType', 'userChannel',  'geoNetwork.continent', \n",
    "                       'geoNetwork.subContinent', 'locationCountry']\n",
    "numerical_columns = ['sessionId','sessionNumber', 'pageViews', 'totalHits', 'sessionStart', 'userId','gclIdPresent']\n",
    "boolean_columns = ['device.isMobile']\n",
    "\n",
    "# Create preprocessing pipelines for different feature types\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values with most frequent\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))    # One-Hot Encoding for categorical features\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values by replacing with median\n",
    "    ('scaler', StandardScaler())  # Scale the numerical features\n",
    "])\n",
    "\n",
    "boolean_pipeline = Pipeline([\n",
    "    ('encoder', OrdinalEncoder())  # Use OrdinalEncoder for boolean features\n",
    "])\n",
    "\n",
    "# Combine all pipelines into one ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', categorical_pipeline, categorical_columns),\n",
    "        ('numerical', numerical_pipeline, numerical_columns),\n",
    "        ('boolean', boolean_pipeline, boolean_columns)\n",
    "    ])\n",
    "\n",
    "# Define the model for regression (XGBRegressor) with best hyperparameters\n",
    "model = XGBRegressor(\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss', \n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    n_estimators=766,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.04,\n",
    "    subsample=0.8823,\n",
    "    colsample_bytree=0.7021,\n",
    "    gamma=0.2306,\n",
    "    min_child_weight=3,\n",
    "    reg_alpha=0.4916,\n",
    "    reg_lambda=1.2001,\n",
    "    scale_pos_weight=5\n",
    ")\n",
    "\n",
    "# Create the full pipeline including preprocessing and modeling\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Prepare the training data\n",
    "X_train = train.drop('purchaseValue', axis=1)\n",
    "y_train = train['purchaseValue']\n",
    "\n",
    "# Train the model\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prepare validation data\n",
    "X = train_df.drop(columns=['purchaseValue'])\n",
    "y = train_df['purchaseValue']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate the model's performance on the validation data\n",
    "score = r2_score(y_val, full_pipeline.predict(X_val))\n",
    "print(\"R-squared score on validation data:\", score)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) for further evaluation\n",
    "mse = mean_squared_error(y_val, full_pipeline.predict(X_val))\n",
    "print(\"Mean Squared Error on validation data:\", mse)\n",
    "\n",
    "# Make predictions on the test data\n",
    "X_test = test  # Test dataset without the target variable\n",
    "test_preds = full_pipeline.predict(X_test)\n",
    "\n",
    "# Ensure predictions are non-negative (if needed, depending on your problem)\n",
    "test_preds = np.clip(test_preds, 0, None)\n",
    "\n",
    "# Prepare the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': subm_df['ID'],  # ID from the sample submission file\n",
    "    'purchaseValue': test_preds  # The predicted purchase values\n",
    "})\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11895149,
     "sourceId": 99546,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.77053,
   "end_time": "2025-07-24T15:16:35.507489",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-24T15:15:39.736959",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
